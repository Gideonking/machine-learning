{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier # Extreme Gradient Boost Classifier\n",
    "from xgboost import plot_importance # Used to plot feature importances from pre-trained model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "data = loadtxt('pima.csv', delimiter = ',')\n",
    "X = data[:,0:8]\n",
    "y = data[:,8]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size = test_size, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  77.9220779221\n"
     ]
    }
   ],
   "source": [
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: \", accuracy * 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the next part we will look at how we can use early stopping to limit overfitting.\n",
    "The XGBoost model can evaluate and report on the performance on a test set for the model\n",
    "during training. It supports this capability by specifying both a test dataset and an evaluation\n",
    "metric on the call to model.fit() when training the model and specifying verbose output\n",
    "(verbose=True). For example, we can report on the binary classification error rate (error) on\n",
    "a standalone test set (eval set) while training an XGBoost model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.660284\n",
      "Will train until validation_0-logloss hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-logloss:0.633188\n",
      "[2]\tvalidation_0-logloss:0.611107\n",
      "[3]\tvalidation_0-logloss:0.592087\n",
      "[4]\tvalidation_0-logloss:0.577545\n",
      "[5]\tvalidation_0-logloss:0.565459\n",
      "[6]\tvalidation_0-logloss:0.552978\n",
      "[7]\tvalidation_0-logloss:0.544117\n",
      "[8]\tvalidation_0-logloss:0.534974\n",
      "[9]\tvalidation_0-logloss:0.529147\n",
      "[10]\tvalidation_0-logloss:0.523495\n",
      "[11]\tvalidation_0-logloss:0.519157\n",
      "[12]\tvalidation_0-logloss:0.513293\n",
      "[13]\tvalidation_0-logloss:0.508292\n",
      "[14]\tvalidation_0-logloss:0.50541\n",
      "[15]\tvalidation_0-logloss:0.502277\n",
      "[16]\tvalidation_0-logloss:0.500996\n",
      "[17]\tvalidation_0-logloss:0.498203\n",
      "[18]\tvalidation_0-logloss:0.496092\n",
      "[19]\tvalidation_0-logloss:0.494517\n",
      "[20]\tvalidation_0-logloss:0.492048\n",
      "[21]\tvalidation_0-logloss:0.490866\n",
      "[22]\tvalidation_0-logloss:0.489825\n",
      "[23]\tvalidation_0-logloss:0.489278\n",
      "[24]\tvalidation_0-logloss:0.487723\n",
      "[25]\tvalidation_0-logloss:0.487428\n",
      "[26]\tvalidation_0-logloss:0.486002\n",
      "[27]\tvalidation_0-logloss:0.486001\n",
      "[28]\tvalidation_0-logloss:0.483862\n",
      "[29]\tvalidation_0-logloss:0.481405\n",
      "[30]\tvalidation_0-logloss:0.48133\n",
      "[31]\tvalidation_0-logloss:0.482662\n",
      "[32]\tvalidation_0-logloss:0.482765\n",
      "[33]\tvalidation_0-logloss:0.481756\n",
      "[34]\tvalidation_0-logloss:0.480243\n",
      "[35]\tvalidation_0-logloss:0.481435\n",
      "[36]\tvalidation_0-logloss:0.480975\n",
      "[37]\tvalidation_0-logloss:0.482346\n",
      "[38]\tvalidation_0-logloss:0.483623\n",
      "[39]\tvalidation_0-logloss:0.484338\n",
      "[40]\tvalidation_0-logloss:0.483427\n",
      "[41]\tvalidation_0-logloss:0.484296\n",
      "[42]\tvalidation_0-logloss:0.483843\n",
      "[43]\tvalidation_0-logloss:0.483442\n",
      "[44]\tvalidation_0-logloss:0.482457\n",
      "Stopping. Best iteration:\n",
      "[34]\tvalidation_0-logloss:0.480243\n",
      "\n",
      "Accuracy:  77.9220779221\n"
     ]
    }
   ],
   "source": [
    "eval_set = [(X_test, y_test)]\n",
    "model.fit(X_train, y_train, eval_metric = \"logloss\", \n",
    "          eval_set = eval_set, verbose = True,\n",
    "          early_stopping_rounds = 10)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy: \", accuracy * 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the next Part we will look at how we calculate the importance of features using XGBoost.\n",
    "A benefit of using ensembles of decision tree methods like gradient boosting is that they can\n",
    "automatically provide estimates of feature importance from a trained predictive model. A\n",
    "trained XGBoost model automatically calculates feature importance on your predictive modeling\n",
    "problem. These importance scores are available in the feature importances member variable\n",
    "of the trained model. For example, they can be printed directly as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04895105  0.24475524  0.05944056  0.08741259  0.04545455  0.18181819\n",
      "  0.16083916  0.17132868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEWCAYAAACOv5f1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlkMufzOzHHL5m5nlkMvfzCyH/j8B60nWvTU0FQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2e72ede8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.feature_importances_)\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the next part we will look at heuristics for best configuring the gradient boosting algorithm.\n",
    "Gradient boosting is one of the most powerful techniques for applied machine learning and as\n",
    "such is quickly becoming one of the most popular. But how do you configure gradient boosting\n",
    "on your problem? A number of configuration heuristics were published in the original gradient\n",
    "boosting papers. They can be summarized as:\n",
    "<ol>\n",
    "    <li>Learning rate or shrinkage (learning rate in XGBoost) should be set to 0.1 or lower,\n",
    "and smaller values will require the addition of more trees. \n",
    "   </li>  \n",
    "    \n",
    "    <li>\n",
    "    The depth of trees (tree depth in XGBoost) should be configured in the range of 2-to-8,\n",
    "where not much benefit is seen with deeper trees.\n",
    "   </li>  \n",
    "   \n",
    "   <li>Row sampling (subsample in XGBoost) should be configured in the range of 30% to 80%\n",
    "of the training dataset, and compared to a value of 100% for no sampling.\n",
    "   </li>  \n",
    "   \n",
    "</ol>\n",
    "\n",
    "These are a good starting points when configuring your model. A good general configuration\n",
    "strategy is as follows:\n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "    Run the default configuration and review plots of the learning curves on the training and\n",
    "validation datasets.\n",
    "    </li>\n",
    "    \n",
    "     <li>\n",
    "   If the system is overlearning, decrease the learning rate and/or increase the number of\n",
    "trees.\n",
    "    </li>\n",
    "    \n",
    "     <li>\n",
    "    If the system is underlearning, speed the learning up to be more aggressive by increasing\n",
    "the learning rate and/or decreasing the number of trees.\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Hyperparameter Tuning\n",
    "The scikit-learn framework provides the capability to search combinations of parameters. This\n",
    "capability is provided in the GridSearchCV class and can be used to discover the best way to\n",
    "configure the model for top performance on your problem. For example, we can define a grid of\n",
    "the number of trees (n estimators) and tree sizes (max depth) to evaluate by defining a grid\n",
    "as:\n",
    "<b>\n",
    "    <br>n_estimators = [50, 100, 150, 200]\n",
    "    <br>max_depth = [2, 4, 6, 8]\n",
    "    <br>param_grid = dict(max_depth=max_depth, n_estimators=n_estimators)\n",
    "</b>\n",
    "\n",
    "And then evaluate each combination of parameters using 10-fold cross-validation as:\n",
    "<b>\n",
    "    <br>kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "    <br>grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold, verbose=1)\n",
    "    <br>result = grid_search.fit(X, label_encoded_y)\n",
    "<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "param_grid = dict(learning_rate=learning_rate)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring = \"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "\n",
    "grid_result = grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.483304 using {'learning_rate': 0.1}\n",
      "-0.689811 (0.000475) with: {'learning_rate': 0.0001}\n",
      "-0.661827 (0.004625) with: {'learning_rate': 0.001}\n",
      "-0.531155 (0.028945) with: {'learning_rate': 0.01}\n",
      "-0.483304 (0.055151) with: {'learning_rate': 0.1}\n",
      "-0.515642 (0.061723) with: {'learning_rate': 0.2}\n",
      "-0.554158 (0.067557) with: {'learning_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
