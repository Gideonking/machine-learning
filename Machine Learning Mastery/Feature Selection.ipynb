{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection:\n",
    "Feature selection is a process where you automatically select those features in your data that\n",
    "contribute most to the prediction variable or output in which you are interested. Having\n",
    "irrelevant features in your data can decrease the accuracy of many models, especially linear\n",
    "algorithms like linear and logistic regression.Three benefits of performing feature selection\n",
    "before modeling your data are:\n",
    "<ul>\n",
    "    <li>Reduces Overfitting: Less redundant data means less opportunity to make decisions\n",
    "        based on noise.\n",
    "    </li>\n",
    "    <li>\n",
    "        Improves Accuracy: Less misleading data means modeling accuracy improves.\n",
    "    </li>\n",
    "    <li>\n",
    "        Reduces Training Time: Less data means that algorithms train faster.\n",
    "    </li>\n",
    "</ul> \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Univariate Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    preg    plas    pres    skin    test    mass    pedi    age    class \n",
       "0       6     148      72      35       0    33.6   0.627     50        1\n",
       "1       1      85      66      29       0    26.6   0.351     31        0\n",
       "2       8     183      64       0       0    23.3   0.672     32        1\n",
       "3       1      89      66      23      94    28.1   0.167     21        0\n",
       "4       0     137      40      35     168    43.1   2.288     33        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Load Data\n",
    "names = [ ' preg ' , ' plas ' , ' pres ' , ' skin ' , ' test ' , ' mass ' , ' pedi ' , ' age ' , ' class ' ]\n",
    "data = pd.read_csv('pima.csv', names = names)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data\n",
    "array = data.values\n",
    "X = array[:, 0:8]\n",
    "y = array[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  111.52   1411.887    17.605    53.108  2175.565   127.669     5.393\n",
      "   181.304]\n"
     ]
    }
   ],
   "source": [
    "# Select Features\n",
    "test = SelectKBest(score_func = chi2, k = 4)\n",
    "fit = test.fit(X, y)\n",
    "\n",
    "# Summarize Scores\n",
    "set_printoptions(precision = 3)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 148.     0.    33.6   50. ]\n",
      " [  85.     0.    26.6   31. ]\n",
      " [ 183.     0.    23.3   32. ]\n",
      " [  89.    94.    28.1   21. ]\n",
      " [ 137.   168.    43.1   33. ]]\n"
     ]
    }
   ],
   "source": [
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features:  3\n",
      "Selected Features:  [ True False False False False  True  True False]\n",
      "Feature Ranking:  [1 2 3 5 6 1 1 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X,y)\n",
    "\n",
    "print(\"Num Features: \", fit.n_features_)\n",
    "print(\"Selected Features: \", fit.support_) \n",
    "print(\"Feature Ranking: \", fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Principal Component Analysis:\n",
    "Principal Component Analysis (or PCA) uses linear algebra to transform the dataset into a\n",
    "compressed form. Generally this is called a data reduction technique. A property of PCA is that\n",
    "you can choose the number of dimensions or principal components in the transformed result. In\n",
    "the example below, we use PCA and select 3 principal components. Learn more about the PCA\n",
    "class in scikit-learn by reviewing the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance:  [ 0.889  0.062  0.026]\n",
      "[[ -2.022e-03   9.781e-02   1.609e-02   6.076e-02   9.931e-01   1.401e-02\n",
      "    5.372e-04  -3.565e-03]\n",
      " [ -2.265e-02  -9.722e-01  -1.419e-01   5.786e-02   9.463e-02  -4.697e-02\n",
      "   -8.168e-04  -1.402e-01]\n",
      " [ -2.246e-02   1.434e-01  -9.225e-01  -3.070e-01   2.098e-02  -1.324e-01\n",
      "   -6.400e-04  -1.255e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca  = PCA(n_components = 3)\n",
    "fit = pca.fit(X)\n",
    "\n",
    "# summarize components\n",
    "print(\"Explained Variance: \", fit.explained_variance_ratio_)\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Feature Importance:\n",
    "Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance\n",
    "of features. In the example below we construct a ExtraTreesClassifier classifier for the Pima\n",
    "Indians onset of diabetes dataset. You can learn more about the ExtraTreesClassifier class 5\n",
    "in the scikit-learn API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we are given an importance score for each attribute where the larger the\n",
    "score, the more important the attribute. The scores suggest at the importance of plas, age\n",
    "and mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.122  0.237  0.097  0.077  0.078  0.137  0.123  0.128]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
